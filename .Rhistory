#in terms of gamma distro params
alpha = v0
beta = v0*w0_2/2
#now , perform gibbs sampling
#set up mat to store estimates + some key variables
n_samps = 10000
ngroups = nrow(EfronMorris)
mu0.loc = ngroups+1
A.loc = ngroups+2
samples = matrix(nrow=n_samps, ncol = (nrow(EfronMorris) + 2))
set.seed(021992)
#initialize by drawing from priors given hyperparams
samples[1,mu0.loc]=rnorm(1,b0,B0)
samples[1,A.loc]=rigamma(1,alpha,beta)
samples[1,1:ngroups]= rnorm(ngroups,
samples[1,mu0.loc],samples[1,A.loc])
samples[1,1:ngroups]=mu.MLE
mu0 = samples[1,mu0.loc]
A = samples[1,A.loc]
#now begin sampling
for (i in 2:n_samps){
if (i %% 100 == 0){
print(i)
}
#load new estimates of mu0 and A for cond. distro of mu_i
#resample group means
for ( j in 1:ngroups){
samples[i,j] = rnorm(1,
(A*EfronMorris$y[j] + sigma2*mu0)/(A + sigma2),
A*sigma2/(A+sigma2))
}
mu_i = samples[i,1:ngroups]
#draw new mu0 with updated posterior
postmean_mu0 = (b0*A + mean(mu_i)*ngroups*B0)/(A + ngroups*B0)
postvar_mu0 = (A*ngroups*B0)/(A + ngroups*B0)
samples[i,mu0.loc] = rnorm(1,postmean_mu0,postvar_mu0)
#draw new A with updated posterior
mu0=samples[i,mu0.loc]
postalpha_A = alpha + ngroups/2
postbeta_A = beta + var(mu_i - mu0)*ngroups/2
samples[i,A.loc] = rigamma(1,postalpha_A,postbeta_A)
A=samples[i,A.loc]
#rinse and repeat
}
#now compute averages to estimate the individual parameters
#compare to JS,MLE.
mu.Gibbs = colMeans(samples[,1:ngroups])
?line
?plot
plot(1:10000,samples[A.loc],type='l')
plot(1:10000,samples[,A.loc],type='l')
plot(1:10000,samples[,mu0.loc],type='l')
plot(1:10000,samples[,1],type='l')
plot(1:10000,samples[,2],type='l')
plot(1:10000,samples[,5],type='l')
plot(1:10000,samples[,7],type='l')
mu.true = EfronMorris$p
MSE.MLE = mean((mu.MLE-mu.true)^2)
MSE.JS =  mean((mu.JS-mu.true)^2)
MSE.Gibbs =  mean((mu.Gibbs-mu.true)^2)
mu.Gibbs
mu.MLE
?npoisson
?poisson
?rpoisson
?rpois
n=100
lambda=1
x = rpois(n,lambda);
max(x)
tabulate(x)
sum(x[x>2])
sum(x[x>3])
x[x>2]
x[x>3]
x[x>3]>0
x[x>3]==0
sum(x>9)
sum(x>2)
ub=3
n=10000
print(ub)
x = rpois(n,lambda)
oob=sum(x>ub) #num out of bound values generated
while (oob>0){
x[x>9] <- rpois(oob,lambda)
oob=sum(x>ub)
print(oob)
}
x = rpois(n,lambda)
oob=sum(x>ub) #num out of bound values generated
while (oob>0){
x[x>ub] <- rpois(oob,lambda)
oob=sum(x>ub)
print(oob)
}
#from 0 to 9
truncPoisson <- function(n,lambda){
ub = 9 #the upper bound of the truncated poisson distro
x = rpois(n,lambda)
oob=sum(x>ub) #num out of bound values generated
while (oob>0){
x[x>ub] <- rpois(oob,lambda)
oob=sum(x>ub)
print(oob)
}
return(x)
}
truncPoisson(10000,8)
x=truncPoisson(10000,8)
truncPoisson <- function(n,lambda){
ub = 9 #the upper bound of the truncated poisson distro
x = rpois(n,lambda)
oob=sum(x>ub) #num out of bound values generated
while (oob>0){
x[x>ub] <- rpois(oob,lambda)
oob=sum(x>ub)
#print(oob)
}
return(x)
}
x=truncPoisson(10000,8)
summary(x)
hist(x)
?seed
x=truncPoisson(10000,5)
hist(x)
?bernoulli
?rbernoulli
rbern
?runiform()
?runif
W = (runif(N)<=prob_treat)
W = (runif(N)<=prob_treat)
N=1000
W = (runif(N)<=prob_treat)
prob_treat=.5
W = (runif(N)<=prob_treat)
W
# Section numbers correspond to assignment page
############################################################
# set your working directory
setwd("C:\\Users\\Jack\\Documents\\Git\\Athey ML homework 1\\AtheyMLhw1") # Jack
#setwd('/home/luis/Downloads/AtheyMLhw1') #Luis
# clear things in RStudio
rm(list = ls())
# Call packages
library(ggplot2)
library(dplyr)
# set seed
set.seed(12345)
############################################################
### ECON 293 Homework 1
# Luis Armona and Jack Blundell
# Stanford University
# Spring 2017
# Section numbers correspond to assignment page
############################################################
# set your working directory
#setwd("C:\\Users\\Jack\\Documents\\Git\\Athey ML homework 1\\AtheyMLhw1") # Jack
setwd('/home/luis/AtheyMLhw1') #Luis
# clear things in RStudio
rm(list = ls())
# Call packages
library(ggplot2)
library(dplyr)
# set seed
set.seed(12345)
install.packages('dplyr')
#setwd("C:\\Users\\Jack\\Documents\\Git\\Athey ML homework 1\\AtheyMLhw1") # Jack
setwd('/home/luis/AtheyMLhw1') #Luis
# clear things in RStudio
rm(list = ls())
# Call packages
library(ggplot2)
library(dplyr)
# set seed
set.seed(12345)
############################################################
# Load data
#let's use / instead of \\ since it should be compatible with both systems (Unix/Windows) #JB: Noted! (I'm new to PC..!)
fname <- 'analysis/input/charitable_withdummyvariables.csv'
char <- read.csv(fname)
attach(char) # attach so don't have to call each time
### Exploratory analysis
dim(char) # 50,083 obs, 63 vars
names(char)
head(char) # Look at first few entries of each var
# Treatment
summary(treatment) # Anyone who got any of the 27 treatments (3 match x 3 match size x 3 reccomended amount)
mean(treatment) # 67% treated
# Gives at all
summary(out_gavedum)
# Giving
summary(out_amountgive) # amount given. Highly skewed
hist(out_amountgive)
hist(out_amountgive[out_amountgive<=10])
reg_ols <- lm(out_amountgive ~ treatment)
summary(reg_ols) # show results, significant at 90% but not 95% level
# Consistent with Table 4 of paper
confint(reg_ols, level=0.95) # CI
#probit regression
gave_probit <- glm(out_gavedum ~ treatment,family=binomial(link='probit'))
#convert coef to derivative
marginal.effect <- mean(dnorm(predict(gave_probit, type = "link")))*coef(gave_probit)
print(marginal.effect)
# look at some potential variables
summary(page18_39)
hist(page18_39[page18_39_missing!=1])
summary(perbush)
hist(perbush[perbush_missing!=1])
#LA: added that we remove ppl missing income info
char_res <- char[ which(page18_39!=-999
& perbush!=-999
& median_hhincome!=-999), ] # drop all those with missings of key variables
detach(char)
attach(char_res) # attach so don't have to call each time
char_res$drop <- 0 # variable telling us to drop or not
# Make threshold rule for dropping (alternatively do with random variable)
char_res$thres <- perbush #+ 0.1*(1+perbush)^2 - 0.1*page18_39*perbush #- page18_39 - page18_39^2 + perbush^2
summary(char_res$thres)
char_res$drop[char_res$thres <= 0.5] <- 1
##############################
#Alternative rule:
#randomly censor individuals
#via a  complex, highly nonlinear fcn  of votes 4 bush in state,
#
ps.fcn <- function(v,c,pg,t){
v_t <- (v-.25)/.5
v_t <- v
ihs_pg <- log(pg + sqrt(pg ^ 2 + 1))/5
#p<- ((2*c*(t*acos(v_t)) + (1-t)*atan(v_t^2))  - .5*exp(v_t) + t*((ihs_i)^4)/4 + (1-t)*(i/10000))/4
p<- (c*(acos(v_t))*atan(v_t^2)  - .5*exp(v_t))/4 + (t*((ihs_pg)) + (1-t))/2
p<- pmin(pmax(0,p),1)
return(p)
}
#story to accompany this fcn: ACLU wants to help those in trouble in "red states" but do not
#feel they can make a difference in really, really red states so target donors less often
plot(seq(0,1,.001),ps.fcn(seq(0,1,.001),2,800,1),ylim=c(0,1))#a plot of the function
lines(seq(0,1,.001),ps.fcn(seq(0,1,.001),1,800,0))
lines(seq(0,1,.001),ps.fcn(seq(0,1,.001),3,200,1))
#char$mibush=char$perbush==-999
#char$perbush[char$mibush]=.5
char_res$ps.true <- ps.fcn(char_res$perbush,char_res$cases,char_res$hpa,char_res$treatment)
ggplot(char_res,aes(x=ps.true))+ stat_ecdf()
set.seed(21)
selection <- runif(nrow(char_res)) <= char_res$ps.true
char.censored <- char_res[selection,] #remove observations via propensity score rule
ggplot(char_res,aes(x=perbush)) + geom_histogram()+xlim(c(0,1))
ggplot(char.censored,aes(x=ps.true)) + geom_histogram() +xlim(c(0,1))
#overlap in true propensity score
ggplot(char.censored,aes(x=ps.true,colour=factor(treatment))) + stat_ecdf()
ggplot(char.censored,aes(x=ps.true,y=hpa,colour=factor(treatment))) + geom_point()
#jack's threshold rule
reg_ols_drop <- lm(out_amountgive ~ treatment, data = char_res_d)
summary(reg_ols_drop)
#Luis' PS generating rule
reg_censored <- lm(out_amountgive ~ treatment, data = char.censored)
summary(reg_censored)
# Old regression results (remember to drop missings to make comparable sample)
reg_ols_comp <- lm(out_amountgive ~ treatment, data = char_res)
summary(reg_ols_comp)
View(char.censored)
char.censored[,3]
head(char.censored[,3])
head(char.censored[,10])
names(char.censored)
names(char.censored)[9]
names(char.censored)[12]
names(char.censored)[15]
names(char.censored)[14]
names(char.censored)[20]
1:10 15:20
1:10 ,15:20
c(1:10 ,15:20)
names(char.censored)[20]
names(char.censored)[23]
covars.all <- char.censored[,c(14:22,23:66)] #skip the state indicator used for summ stats
View(covars.all)
covars.all <- char.censored[,c(14:22,23:63)] #skip the state indicator used for summ stats
View(char.censored)
View(covars.all)
formula <- 'treatment ~ ' + paste(names(covars.all),sep='+')
ps.formula <- paste('treatment ~ ' paste(names(covars.all),collapse='+'),sep='')
ps.formula <- paste('treatment ~ ', paste(names(covars.all),collapse='+'),sep='')
covars.all <- char.censored[,c(14:22,23:63)] #skip the state indicator used for summ stats
ps.formula <- paste('treatment ~ ', paste(names(covars.all),collapse='+'),sep='')
m.ps <- glm(ps.formula,
family = binomial(), data = char.censored)
summary(m.ps)
?glm
?predict
char.censored$ps.est <- predict(m.ps)
summary(char.censored$ps.est)
char.censored$ps.est <- predict(m.ps,type='response')
?reshape
?melt
??melt
library(reshape2)
char.censored$ps.est <- predict(m.ps,type='response')
summary(m.ps)
summary(char.censored$ps.est)
?melt
melt(char.censored[,c('ps.true','ps.est')])
ggplot(melt(char.censored[,c('ps.true','ps.est')],aes(x=value,colour=variable)) + geom_histogram(alpha=.2)
char.censored$w.ate[char.censored$treatment == 1] <-  1/char.censored$ps.true[char.censored$treatment == 1]
char.censored$w.ate[char.censored$treatment == 0] <-  ( 1 / (1 - char.censored$ps.true[char.censored$treatment == 0]))
pweight.reg <- lm(out_amountgive ~ treatment, weights = w.ate, data = char.censored)
summary(pweight.reg)
ggplot(melt(char.censored[,c('ps.true','ps.est')]),aes(x=value,colour=variable)) + geom_histogram(alpha=.2)
ggplot(melt(char.censored[,c('ps.true','ps.est')]),aes(x=value,colour=variable)) + geom_density(alpha=.2)
summary(char.censored$ps.est)
summary(char.censored$ps.true)
char.censored$w.ate[char.censored$treatment == 1] <-  1/char.censored$ps.est[char.censored$treatment == 1]
char.censored$w.ate[char.censored$treatment == 0] <-  ( 1 / (1 - char.censored$ps.est[char.censored$treatment == 0]))
char.censored$w.ate[char.censored$treatment == 1] <-  1/char.censored$ps.est[char.censored$treatment == 1]
char.censored$w.ate[char.censored$treatment == 0] <-  ( 1 / (1 - char.censored$ps.est[char.censored$treatment == 0]))
#regular propensity score weighting
ate.ps <- mean(char.censored$out_amountgive[char.censored$treatment==1]*
char.censored$w.ate[char.censored$treatment == 1]) -
mean(char.censored$out_amountgive[char.censored$treatment==0]*
char.censored$w.ate[char.censored$treatment == 1])
#regular propensity score weighting
ate.ps <- mean(char.censored$out_amountgive[char.censored$treatment==1]*
char.censored$w.ate[char.censored$treatment == 1]) -
mean(char.censored$out_amountgive[char.censored$treatment==0]*
char.censored$w.ate[char.censored$treatment == 0])
reg_ols_comp <- lm(out_amountgive ~ treatment, data = char_res)
summary(reg_ols_comp)
ate.true <- reg_ols_comp$coefficients[2]
ols.formula <- paste('out_amountgive ~ treatment +', paste(names(covars.all),collapse='+'),sep='')
reg.ols <- lm(ols.formula, data=char.censored)
print(reg.ols$coefficients)
print(reg.ols$coefficients['treatment'])
?lm
pweight.reg <- lm(ols.formula, weights = w.ate, data = char.censored)
summary(pweight.reg)
print(reg.ols$coefficients['treatment'])
print(reg.ols$coefficients['treatment'])
#first, estimate the propensity score with a logit regression using all covars
#since in this exercise we should not know the "ground truth" propensity score
covars.all <- names(char.censored[,c(14:22,23:63)]) #skip the state indicator used for summ stats
ps.formula <- paste('treatment ~ ', paste(covars.all,collapse='+'),sep='')
m.ps <- glm(ps.formula,
family = binomial(), data = char.censored)
char.censored$ps.est <- predict(m.ps,type='response')
summary(char.censored$ps.est)
#compare estimated p-score w/ real p-score
ggplot(melt(char.censored[,c('ps.true','ps.est')]),aes(x=value,colour=variable)) + geom_density(alpha=.2)
char.censored$w.ate[char.censored$treatment == 1] <-  1/char.censored$ps.est[char.censored$treatment == 1]
char.censored$w.ate[char.censored$treatment == 0] <-  ( 1 / (1 - char.censored$ps.est[char.censored$treatment == 0]))
#regular propensity score weighting
ate.ps <- mean(char.censored$out_amountgive[char.censored$treatment==1]*
char.censored$w.ate[char.censored$treatment == 1]) -
mean(char.censored$out_amountgive[char.censored$treatment==0]*
char.censored$w.ate[char.censored$treatment == 0])
print(ate.ps)
#gives a negative score!
# direct regression analysis ATE;
# control for Xs linearly
ols.formula <- paste('out_amountgive ~ treatment +', paste(covars.all,collapse='+'),sep='')
reg.ols <- lm(ols.formula, data=char.censored)
print(reg.ols$coefficients['treatment'])
library(glmnet)
install.packages('glmnet')
library(glmnet)
?glmnet
?cv.glmnet
ps.m.pen <- cv.glmnet(covars.all,char.censored$out_amountgive, family='binomial')
ps.m.pen <- cv.glmnet(covars.all,char.censored$out_amountgive)
ps.m.pen <- glmnet(covars.all,char.censored$out_amountgive, family='binomial')
dim(covars.all)
covars.all <- char.censored[,c(14:22,23:63)] #skip the state indicator used for summ stats
dim(covars.all)
ps.m.pen <- cv.glmnet(covars.all,char.censored$out_amountgive, family='binomial',nfolds=5)
ps.m.pen <- cv.glmnet(covars.all,char.censored$treatment, family='binomial',nfolds=5)
char.censored$treatment
as.double(char.censored$treatment)
ps.m.pen <- cv.glmnet(covars.all,char.censored$treatment, family='binomial')
ps.m.pen <- cv.glmnet(as.matrix(covars.all),char.censored$treatment, family='binomial')
ps.m.pen$lambda
plot(ps.m.pen)
ps.m.pen$cvm
ps.m.pen$lambda.min
min(ps.m.pen$lambda)
ps.m.cv <- cv.glmnet(as.matrix(covars.all),char.censored$treatment, family='binomial')
coef(ps.m.cv,s='lambda.min')
predict(ps.m.cv,s='lambda.min')
predict(ps.m.cv,as.matrix(covars.all),s='lambda.min')
char.censored$ps.lasso <- predict(ps.m.cv,as.matrix(covars.all),s='lambda.min')
ggplot(melt(char.censored[,c('ps.true','ps.est','ps.lasso')]),aes(x=value,colour=variable)) + geom_density(alpha=.2)
summary(char.censored$ps.lasso)
is.nan(char.censored$ps.lasso)
mean(is.nan(char.censored$ps.lasso))
mean(is.nan(char.censored$ps.true))
mean(is.nan(char.censored$ps.est))
mean(is.na(char.censored$ps.est))
mean(is.na(char.censored$ps.lasso))
#propensity score weighting
ate.ps.lasso <- mean(char.censored$out_amountgive[char.censored$treatment==1]*
char.censored$w.ate.lasso[char.censored$treatment == 1]) -
mean(char.censored$out_amountgive[char.censored$treatment==0]*
char.censored$w.ate.lasso[char.censored$treatment == 0])
print(ate.ps.lasso)
#redo above methods (weighted mean, DR weights)
char.censored$w.ate.lasso[char.censored$treatment == 1] <-  1/char.censored$ps.lasso[char.censored$treatment == 1]
char.censored$w.ate.lasso[char.censored$treatment == 0] <-  ( 1 / (1 - char.censored$ps.lasso[char.censored$treatment == 0]))
#propensity score weighting
ate.ps.lasso <- mean(char.censored$out_amountgive[char.censored$treatment==1]*
char.censored$w.ate.lasso[char.censored$treatment == 1]) -
mean(char.censored$out_amountgive[char.censored$treatment==0]*
char.censored$w.ate.lasso[char.censored$treatment == 0])
print(ate.ps.lasso)
ate.ps
#DR IPR weighting
pweight.lasso.reg <- lm(ols.formula, weights = w.ate.lasso, data = char.censored)
summary(pweight.reg)
print(reg.ols$coefficients['treatment'])
reg.ols$coefficients
ate.true
print(pweight.reg$coefficients['treatment'])
print(reg.ols$coefficients['treatment'])
print(pweight.lasso.reg$coefficients['treatment'])
#DR IPR weighting
pweight.lasso.reg <- lm(ols.formula, weights = w.ate.lasso, data = char.censored)
summary(pweight.reg)
print(pweight.lasso.reg$coefficients['treatment'])
pweight.lasso.reg <- lm(ols.formula, weights = w.ate.lasso, data = char.censored)
#propensity score weighting
ate.ps.lasso <- mean(char.censored$out_amountgive[char.censored$treatment==1]*
char.censored$w.ate.lasso[char.censored$treatment == 1]) -
mean(char.censored$out_amountgive[char.censored$treatment==0]*
char.censored$w.ate.lasso[char.censored$treatment == 0])
print(ate.ps.lasso)
summary(w.ate.lasso)
summary(char.censored$w.ate.lasso)
summary(char.censored$ps.lasso)
char.censored$ps.lasso <- predict(ps.m.cv,as.matrix(covars.all),s='lambda.min',type='response')
ggplot(melt(char.censored[,c('ps.true','ps.est','ps.lasso')]),aes(x=value,colour=variable)) + geom_density(alpha=.2)
char.censored$w.ate.lasso[char.censored$treatment == 1] <-  1/char.censored$ps.lasso[char.censored$treatment == 1]
char.censored$w.ate.lasso[char.censored$treatment == 0] <-  ( 1 / (1 - char.censored$ps.lasso[char.censored$treatment == 0]))
ate.ps.lasso <- mean(char.censored$out_amountgive[char.censored$treatment==1]*
char.censored$w.ate.lasso[char.censored$treatment == 1]) -
mean(char.censored$out_amountgive[char.censored$treatment==0]*
char.censored$w.ate.lasso[char.censored$treatment == 0])
print(ate.ps.lasso)
pweight.lasso.reg <- lm(ols.formula, weights = w.ate.lasso, data = char.censored)
summary(pweight.reg)
print(pweight.lasso.reg$coefficients['treatment'])
p.fac = rep(1, ncol(covars.all))
lasso.reg <- cv.glmnet(as.matrix(cbind(char.censored$treatment,covars.all)),char.censored$out_amountgive,penalty.factor = p.fac)
coef(lasso.reg,s='lambda.min')
coef(lasso.reg,s='lambda.min')['treatment']
lasso.coef<-coef(lasso.reg,s='lambda.min')
print(lasso.coef['treatment'])
print(lasso.coef[2])
print(lasso.coef)
print(lasso.coef['treatment',])
print(lasso.coef['char.censored$treatment',])
ate.true
coef(pweight.lasso.reg)
names(coef(pweight.lasso.reg)[!is.na(coef(pweight.lasso.reg))])
p.rf <-
names(coef(ps.m.cv,s='lambda.min')[!is.na(coef(pweight.lasso.reg,s='lambda.min'))])
names(coef(ps.m.cv,s='lambda.min')[!is.na(coef(pweight.lasso.reg,s='lambda.min'))])
names(coef(ps.m.cv,s='lambda.min'))
row.names(coef(ps.m.cv,s='lambda.min'))
row.names(coef(ps.m.cv,s='lambda.min')[!is.na(coef(pweight.lasso.reg,s='lambda.min'))]))
row.names(coef(ps.m.cv,s='lambda.min')[!is.na(coef(pweight.lasso.reg,s='lambda.min'))])
psreg.vars<-rownames(coef(ps.m.cv,s='lambda.min'))
psreg.vars
!is.na(coef(ps.m.cv,s='lambda.min'))
coef(ps.m.cv,s='lambda.min')
coef(ps.m.cv,s='lambda.min')[2]
coef(ps.m.cv,s='lambda.min')[7]
psreg.vars[coef(ps.m.cv,s='lambda.min')==0]
coef(ps.m.cv,s='lambda.min')==0
psreg.vars[coef(ps.m.cv,s='lambda.min')!=0]
?is.logical
as.logical(coef(ps.m.cv,s='lambda.min')!=0)
psreg.vars[as.logical(coef(ps.m.cv,s='lambda.min')!=0)]
yreg.rf.cv<-cv.glmnet(as.matrix(covars.all),char.censored$out_amountgive)
summary(yreg.rf.cv,s='lambda.min')
coef(yreg.rf.cv,s='lambda.min')
yreg.vars<-rownames(coef(yreg.rf.cv,s='lambda.min'))
yreg.vars<-yreg.vars[as.logical(coef(yreg.rf.cv,s='lambda.min')!=0)]
yreg.vars
psreg.vars
psreg.vars<-rownames(coef(ps.m.cv,s='lambda.min'))
psreg.vars<-psreg.vars[as.logical(coef(ps.m.cv,s='lambda.min')!=0)]
psreg.vars
ds.vars <- set(yreg.vars,psreg.vars)
ds.vars <- union(yreg.vars,psreg.vars)
ds.vars <- ds.vars[-1]#remove intercept
psreg.vars<-rownames(coef(ps.m.cv,s='lambda.min'))
psreg.vars<-psreg.vars[as.logical(coef(ps.m.cv,s='lambda.min')!=0)]
#reduced form outcome reg
yreg.rf.cv<-cv.glmnet(as.matrix(covars.all),char.censored$out_amountgive)
yreg.vars<-rownames(coef(yreg.rf.cv,s='lambda.min'))
yreg.vars<-yreg.vars[as.logical(coef(yreg.rf.cv,s='lambda.min')!=0)]
ds.vars <- union(yreg.vars,psreg.vars)
ds.vars <- ds.vars[-1]#remove intercept
paste('treatment ~ ', paste(names(covars.all),collapse='+'),sep='')
doubleselect.formula <- paste('out_amountgive ~ treatment + ',paste(ds.vars,collapse='+'),sep='')
reg.DoubleSelection <- lm(doubleselect.formula,data=char.censored)
summary(reg.DoubleSelection)
print(reg.DoubleSelection$coefficients['treatment'])
ate.true
print(lasso.coef['char.censored$treatment',])
print(pweight.lasso.reg$coefficients['treatment'])
print(pweight.reg$coefficients['treatment'])
print(reg.ols$coefficients['treatment'])
